âš™ï¸ Installation et Configuration

**1. Cloner le projet**

git clone https://github.com/AI-Sisters/test_technique.git

cd legal_rag_poc

**2. CrÃ©er lâ€™environnement**

conda create -n legal_rag_env python=3.11 -y
conda activate legal_rag_env
pip install -r requirements.txt

**3. Configurer les clÃ©s API**

CrÃ©e un fichier .env Ã  la racine du projet contenant ta clÃ© OpenAI :
OPENAI_API_KEY=sk-xxxx

ğŸ’¡ Pour Claude, Gemini ou un autre LLM, modifie src/rag.py pour pointer vers une autre API compatible (Anthropic, Mistral, etc.).

ğŸš€ Lancement de lâ€™application

streamlit run streamlit_app.py
Puis ouvre http://localhost:8501

**ğŸ§© Structure du projet
**
legal_rag_poc/
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ pages/
â”‚ â”œâ”€â”€ 1_Chat.py
â”‚ â””â”€â”€ 2_Gestion_docs.py
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ embeddings.py
â”‚ â”œâ”€â”€ vectorstore.py
â”‚ â”œâ”€â”€ rag.py
â”‚ â”œâ”€â”€ config.py
â”‚ â”œâ”€â”€ security.py
â”‚ â””â”€â”€ persist.py
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ uploads/
â”‚ â”œâ”€â”€ vectorstore/
â”‚ â””â”€â”€ chat_history.json
â””â”€â”€ tests/
â”œâ”€â”€ test_smoke.py
â””â”€â”€ test_rag_guardrails.py

ğŸ§  Fonctionnement

Lâ€™utilisateur charge des documents (.txt, .csv, .html)

Le texte est nettoyÃ©, segmentÃ©, puis vectorisÃ© (embeddings)

Ã€ chaque question :

Les passages les plus pertinents sont recherchÃ©s dans la base vectorielle

Le LLM gÃ©nÃ¨re une rÃ©ponse fondÃ©e uniquement sur ces passages

Lâ€™historique des conversations est enregistrÃ© localement dans data/chat_history.json

ğŸ§ª Tests

Pour exÃ©cuter tous les tests :
python -m pytest -s -q

Tests inclus

test_smoke.py â†’ VÃ©rifie que le pipeline RAG complet fonctionne
test_rag_guardrails.py â†’ VÃ©rifie quâ€™aucune rÃ©ponse nâ€™est gÃ©nÃ©rÃ©e hors du corpus interne

Exemple de sortie :
RÃ©ponse LLM : La clause de non-concurrence dure 12 mois aprÃ¨s la rupture du contrat.
âœ… OK

ğŸ” SÃ©curitÃ©
Mesures dÃ©jÃ  en place

DonnÃ©es stockÃ©es uniquement en local dans data/

Aucun envoi des documents vers Internet

API LLM utilisÃ©e uniquement pour embeddings et gÃ©nÃ©ration de rÃ©ponses

DonnÃ©es anonymisÃ©es pour la PoC

Session utilisateur temporaire (timeout)

Aucun log contenant de donnÃ©es sensibles

AmÃ©liorations prÃ©vues

ğŸ”’ Chiffrement des fichiers et embeddings (AES-256)

ğŸ”‘ Authentification unique (SSO)

ğŸ§© Gestion des rÃ´les et droits dâ€™accÃ¨s

ğŸ“œ Audit log complet des accÃ¨s et requÃªtes

ğŸ›¡ï¸ HÃ©bergement on-premise ou cloud souverain

ğŸ“ˆ Monitoring et alertes de sÃ©curitÃ©

**ğŸ—ºï¸ Roadmap**

**Phase 1 â€“ PoC (terminÃ©e âœ…)**
 RAG local avec OpenAI embeddings

 Interface Streamlit (2 pages)

 Upload et vectorisation automatique

 Historique conversationnel persistant

 Tests end-to-end et anti-hallucination

**Phase 2 â€“ Fiabilisation ğŸ”§**
 Passage complet Ã  ChromaDB ou Qdrant serveur

 Nettoyage et validation automatique des mÃ©tadonnÃ©es

 Journalisation et gestion des erreurs

 Tests unitaires automatisÃ©s (CI/CD)

**Phase 3 â€“ SÃ©curitÃ© & ScalabilitÃ© ğŸ”**
 Authentification SSO

 Chiffrement complet des donnÃ©es

 Audit logs + supervision

 Multi-utilisateurs isolÃ©s

**Phase 4 â€“ Intelligence amÃ©liorÃ©e ğŸ§ **
 Hybrid Search (texte + sÃ©mantique)

 Reranking (BGE / ColBERT)

 Fine-tuning sur corpus juridique

 MÃ©moire conversationnelle par utilisateur

**ğŸ“š Technologies clÃ©s
**
Interface : Streamlit
LLM : OpenAI GPT-4 (API)
Vectorisation : SentenceTransformers / OpenAI embeddings
Stockage vectoriel : Qdrant ou ChromaDB
Tests : Pytest
Configuration : dotenv + Pydantic

ğŸ‘¤ Auteur

DÃ©veloppÃ© par Ilan Schwarz (2025)
Projet de dÃ©monstration pour validation technique â€“ Cabinet dâ€™avocats, PoC confidentiel.
